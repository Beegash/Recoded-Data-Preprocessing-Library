{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ifozmen/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ifozmen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/ifozmen/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/ifozmen/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import rdatapp as dpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CategoricalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  Category\n",
      "0        A\n",
      "1        B\n",
      "2        A\n",
      "3        C\n",
      "4        B\n",
      "DataFrame after one-hot encoding:\n",
      "   Category_A  Category_B  Category_C\n",
      "0         1.0         0.0         0.0\n",
      "1         0.0         1.0         0.0\n",
      "2         1.0         0.0         0.0\n",
      "3         0.0         0.0         1.0\n",
      "4         0.0         1.0         0.0\n",
      "Original DataFrame:\n",
      "  Category\n",
      "0        A\n",
      "1        B\n",
      "2        A\n",
      "3        C\n",
      "4        B\n",
      "DataFrame after label encoding:\n",
      "   Category\n",
      "0         0\n",
      "1         1\n",
      "2         0\n",
      "3         2\n",
      "4         1\n"
     ]
    }
   ],
   "source": [
    "dfcategorical = dpl.pd.DataFrame({'Category': ['A', 'B', 'A', 'C', 'B']})\n",
    "\n",
    "# One-hot encoding test case\n",
    "print(\"Original DataFrame:\")\n",
    "print(dfcategorical)\n",
    "df_one_hot = dpl.CategoricalEncoder.one_hot_encode(dfcategorical, 'Category')\n",
    "print(\"DataFrame after one-hot encoding:\")\n",
    "print(df_one_hot)\n",
    "\n",
    "# Label encoding test case\n",
    "dfcategorical = dpl.pd.DataFrame({'Category': ['A', 'B', 'A', 'C', 'B']})  # Original DF again for label encoding\n",
    "print(\"Original DataFrame:\")\n",
    "print(dfcategorical)\n",
    "df_label = dpl.CategoricalEncoder.label_encode(dfcategorical, 'Category')\n",
    "print(\"DataFrame after label encoding:\")\n",
    "print(df_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataTypeConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  Values\n",
      "0      1\n",
      "1      2\n",
      "2      3\n",
      "3      4\n",
      "4      5\n",
      "<class 'str'>\n",
      "DataFrame after converting to numeric:\n",
      "   Values\n",
      "0       1\n",
      "1       2\n",
      "2       3\n",
      "3       4\n",
      "4       5\n",
      "<class 'numpy.int64'>\n",
      "Original DataFrame:\n",
      "  Values\n",
      "0      1\n",
      "1      2\n",
      "2      3\n",
      "3      4\n",
      "4      5\n",
      "<class 'str'>\n",
      "DataFrame after converting to categorical:\n",
      "  Values\n",
      "0      1\n",
      "1      2\n",
      "2      3\n",
      "3      4\n",
      "4      5\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "dfdatatype = dpl.pd.DataFrame({'Values': ['1', '2', '3', '4', '5']})\n",
    "\n",
    "# Numeric conversion test case\n",
    "print(\"Original DataFrame:\")\n",
    "print(dfdatatype)\n",
    "print( type(dfdatatype['Values'][0]))\n",
    "df_numeric = dpl.DataTypeConverter.to_numeric(dfdatatype, 'Values')\n",
    "print(\"DataFrame after converting to numeric:\")\n",
    "print(df_numeric)\n",
    "print(type(df_numeric['Values'][0]))\n",
    "\n",
    "# Categorical conversion test case\n",
    "dfdatatype = dpl.pd.DataFrame({'Values': ['1', '2', '3', '4', '5']})  # Original DF again for categorical conversion\n",
    "print(\"Original DataFrame:\")\n",
    "print(dfdatatype)\n",
    "print( type(dfdatatype['Values'][0]))\n",
    "df_categorical = dpl.DataTypeConverter.to_categorical(dfdatatype, 'Values')\n",
    "print(\"DataFrame after converting to categorical:\")\n",
    "print(df_categorical)\n",
    "print(type(df_categorical['Values'][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DateTimeHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "        Dates\n",
      "0  2023-01-01\n",
      "1  2023-02-01\n",
      "2  2023-03-01\n",
      "DataFrame after converting to datetime:\n",
      "       Dates\n",
      "0 2023-01-01\n",
      "1 2023-02-01\n",
      "2 2023-03-01\n",
      "DataFrame after extracting date parts:\n",
      "       Dates  Dates_year  Dates_month  Dates_day\n",
      "0 2023-01-01        2023            1          1\n",
      "1 2023-02-01        2023            2          1\n",
      "2 2023-03-01        2023            3          1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dfdate = dpl.pd.DataFrame({'Dates': ['2023-01-01', '2023-02-01', '2023-03-01']})\n",
    "\n",
    "# Datetime conversion test case\n",
    "print(\"Original DataFrame:\")\n",
    "print(dfdate)\n",
    "df_datetime = dpl.DateTimeHandler.to_datetime(dfdate, 'Dates')\n",
    "print(\"DataFrame after converting to datetime:\")\n",
    "print(df_datetime)\n",
    "\n",
    "# Extract date parts test case\n",
    "print(\"DataFrame after extracting date parts:\")\n",
    "df_date_parts = dpl.DateTimeHandler.extract_date_parts(df_datetime, 'Dates')\n",
    "print(df_date_parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FeatureEngineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Values\n",
      "0       1\n",
      "1       2\n",
      "2       3\n",
      "3       4\n",
      "4       5\n",
      "DataFrame after creating new feature:\n",
      "   Values  Values_new\n",
      "0       1           2\n",
      "1       2           4\n",
      "2       3           6\n",
      "3       4           8\n",
      "4       5          10\n"
     ]
    }
   ],
   "source": [
    "dffeature = dpl.pd.DataFrame({'Values': [1, 2, 3, 4, 5]})\n",
    "\n",
    "# New feature creation test case\n",
    "print(\"Original DataFrame:\")\n",
    "print(dffeature)\n",
    "df_new_feature = dpl.FeatureEngineer.create_new_feature(dffeature, 'Values', lambda x: x * 2)\n",
    "print(\"DataFrame after creating new feature:\")\n",
    "print(df_new_feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MissingValueHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame with missing values:\n",
      "     A\n",
      "0  1.0\n",
      "1  2.0\n",
      "2  NaN\n",
      "3  4.0\n",
      "4  5.0\n",
      "DataFrame after imputing mean:\n",
      "     A\n",
      "0  1.0\n",
      "1  2.0\n",
      "2  3.0\n",
      "3  4.0\n",
      "4  5.0\n",
      "DataFrame after imputing median:\n",
      "     A\n",
      "0  1.0\n",
      "1  2.0\n",
      "2  3.0\n",
      "3  4.0\n",
      "4  5.0\n",
      "DataFrame after imputing constant value:\n",
      "      A\n",
      "0   1.0\n",
      "1   2.0\n",
      "2  42.0\n",
      "3   4.0\n",
      "4   5.0\n",
      "DataFrame after deleting missing values:\n",
      "     A\n",
      "0  1.0\n",
      "1  2.0\n",
      "3  4.0\n",
      "4  5.0\n"
     ]
    }
   ],
   "source": [
    "df_missing = dpl.pd.DataFrame({'A': [1, 2, None, 4, 5]})\n",
    "\n",
    "# Impute mean test case\n",
    "print(\"Original DataFrame with missing values:\")\n",
    "print(df_missing)\n",
    "df_mean_imputed = dpl.MissingValueHandler.impute_mean(df_missing, 'A')\n",
    "print(\"DataFrame after imputing mean:\")\n",
    "print(df_mean_imputed)\n",
    "\n",
    "# Impute median test case\n",
    "df_missing = dpl.pd.DataFrame({'A': [1, 2, None, 4, 5]})\n",
    "df_median_imputed = dpl.MissingValueHandler.impute_median(df_missing, 'A')\n",
    "print(\"DataFrame after imputing median:\")\n",
    "print(df_median_imputed)\n",
    "\n",
    "# Impute constant test case\n",
    "df_missing = dpl.pd.DataFrame({'A': [1, 2, None, 4, 5]})\n",
    "df_constant_imputed = dpl.MissingValueHandler.impute_constant(df_missing, 'A', 42)\n",
    "print(\"DataFrame after imputing constant value:\")\n",
    "print(df_constant_imputed)\n",
    "\n",
    "# Delete missing values test case\n",
    "df_missing = dpl.pd.DataFrame({'A': [1, 2, None, 4, 5]})\n",
    "df_deleted_missing = dpl.MissingValueHandler.delete_missing(df_missing, 'A')\n",
    "print(\"DataFrame after deleting missing values:\")\n",
    "print(df_deleted_missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OutlierHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Values\n",
      "0       1\n",
      "1       2\n",
      "2       3\n",
      "3     100\n",
      "4       5\n",
      "5       6\n",
      "6       7\n",
      "DataFrame after removing outliers:\n",
      "   Values\n",
      "0       1\n",
      "1       2\n",
      "2       3\n",
      "4       5\n",
      "5       6\n",
      "6       7\n"
     ]
    }
   ],
   "source": [
    "dfoutlier = dpl.pd.DataFrame({'Values': [1, 2, 3, 100, 5, 6, 7]})\n",
    "\n",
    "# IQR outlier detection test case\n",
    "print(\"Original DataFrame:\")\n",
    "print(dfoutlier)\n",
    "df_no_outliers = dpl.OutlierHandler.iqr_outlier_detection(dfoutlier, 'Values')\n",
    "print(\"DataFrame after removing outliers:\")\n",
    "print(df_no_outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "This is a Sample text, with punctuations! and STOP words.\n",
      "Cleaned text:\n",
      "sample text punctuation stop word\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a Sample text, with punctuations! and STOP words.\"\n",
    "\n",
    "# Text cleaning test case\n",
    "text_cleaner = dpl.TextCleaner()\n",
    "print(\"Original text:\")\n",
    "print(text)\n",
    "cleaned_text = text_cleaner.clean_text(text)\n",
    "print(\"Cleaned text:\")\n",
    "print(cleaned_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
